{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdd0e142-4e0f-48c1-9ed1-80329b306f2e",
   "metadata": {},
   "source": [
    "# BERT_trainer_1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a7db9f-bd36-4f26-9e07-690b6ba50618",
   "metadata": {},
   "source": [
    "### Import Training Utilities, Metrics, and Setup Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60e2eef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, BertTokenizer, BertConfig, Trainer\n",
    "from sklearn.metrics import cohen_kappa_score \n",
    "from datasets import Dataset  \n",
    "from pathlib import Path \n",
    "import pandas as pd  \n",
    "import numpy as np\n",
    "import itertools  \n",
    "import warnings  \n",
    "import sys, os \n",
    "\n",
    "# Hide warnings to keep notebook output clean\n",
    "warnings.filterwarnings('ignore')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8a2aee-ab36-43af-8409-78b17ece0865",
   "metadata": {},
   "source": [
    "### Environment Flags to Ensure Stable Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42d76cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"  # Prevents parallel tokenizer threads — avoids potential race conditions or console spam\n",
    "os.environ[\"TORCHINDUCTOR_DISABLE\"] = \"1\"       # Disables TorchInductor (experimental compiler backend) to ensure compatibility\n",
    "os.environ[\"TORCH_COMPILE_DISABLE\"] = \"1\"       # Disables PyTorch 2.0's torch.compile functionality (can cause issues in custom models)\n",
    "os.environ[\"TORCHDYNAMO_DISABLE\"] = \"1\"         # Turns off TorchDynamo, another dynamic optimization engine in PyTorch "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d30c79-c5ce-4677-91bb-0f3e784ff21e",
   "metadata": {},
   "source": [
    "### Set Project Root Directory and Add to Python Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6368736",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))  # Define the root directory two levels above the current working directory\n",
    "sys.path.append(ROOT_DIR)   # Add the root directory to Python's module search path so that custom modules can be imported"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246b775d-5b19-46bd-a767-019e9b5bc0c7",
   "metadata": {},
   "source": [
    "### Import Core Project Modules and Model Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7908e127",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "# Project-specific configuration: paths for data and output storage\n",
    "from config import DATA_DIR, RESULTS_DIR  \n",
    "\n",
    "# Import MoE and BERT model components from custom BERT_utils script\n",
    "from scripts.BERT.BERT_utils_1 import (\n",
    "    map_essay_set_to_expert,\n",
    "    freeze_bert_layers,\n",
    "    BertLayerWithMoE,\n",
    "    add_expert_mask,\n",
    "    MoEFeedForward,\n",
    "    data_collator,\n",
    "    MoeBERTScorer,\n",
    "    MoeBERTModel,\n",
    "    preprocess\n",
    ")\n",
    "\n",
    "# Import utility functions for data processing and scoring\n",
    "from scripts.utils import denormalize_score , generate_train7_test1_splits     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2834d85d-72f7-4c15-b971-ef3c8b0595bc",
   "metadata": {},
   "source": [
    "### Load Essay Dataset from TSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67a4b566-7d0d-45c9-9ec4-70a6e78c2e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the essay dataset as a pandas DataFrame.\n",
    "df = pd.read_csv(f\"{DATA_DIR}/dataset.tsv\", delimiter=\"\\t\", encoding='ISO-8859-1')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff68017-f32c-43e8-aba8-d4fab15dbf96",
   "metadata": {},
   "source": [
    "### Set Device for Computation (GPU if Available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9112d502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA device count: 1\n",
      "Current device: 0 - NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# Use GPU (CUDA) if available; otherwise fallback to CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  \n",
    "\n",
    "# Print how many CUDA-enabled GPUs are detected\n",
    "print(f\"CUDA device count: {torch.cuda.device_count()}\")\n",
    "\n",
    "# Show the index and name of the active GPU (if one is available)\n",
    "print(f\"Current device: {torch.cuda.current_device()} - {torch.cuda.get_device_name(torch.cuda.current_device())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b76ffe8-e0f4-4889-bd3f-075e264e4e42",
   "metadata": {},
   "source": [
    "### Define Hyperparameter Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f35b911",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_space = {\n",
    "    \"learning_rate\": [5e-5],    # Learning rates to try\n",
    "    \"batch_size\": [8],          # Per-device batch size\n",
    "    \"epochs\": [5],              # Training epochs\n",
    "    \"dropout\": [0.2],           # Dropout rate\n",
    "    \"num_experts\": [7],         # Experts per MoE layer\n",
    "    \"aux_loss_weight\": [0],     # Weight for auxiliary loss\n",
    "    \"unfrozen_layers\": [2],     # Unfrozen BERT layers\n",
    "    \"top_k\": [2],               # Experts selected per token\n",
    "    \"grad_accum_steps\": [4]     # gradient accumulation steps\n",
    "}\n",
    "# Generate all possible combinations of hyperparameters\n",
    "config_list = list(itertools.product(*config_space.values()))\n",
    "\n",
    "# Store the corresponding keys to map each config tuple\n",
    "config_keys = list(config_space.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0e4574-cbda-4a3b-b56f-e87960c1a47b",
   "metadata": {},
   "source": [
    "### Load Existing Results (If Any) to Avoid Redundant Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d618640",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = Path(f\"{RESULTS_DIR}/BERT/BERT_results_1.csv\")  # Path to CSV where previous results are saved\n",
    "\n",
    "if results_path.exists():\n",
    "    existing_df = pd.read_csv(results_path)  # Load previously saved results\n",
    "    existing_configs = existing_df[config_keys].to_dict(\"records\")  # Extract existing configurations to check for duplicates\n",
    "else:\n",
    "    existing_df = None                     # No existing results file found\n",
    "    existing_configs = []                  # Start fresh with an empty config list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fc0017-ee7d-45fc-974f-2357de234414",
   "metadata": {},
   "source": [
    "### Run Cross-Prompt MoE-BERT Experiments Over All Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efdb050d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ---------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Running Config 1/1: {'learning_rate': 5e-05, 'batch_size': 8, 'epochs': 1, 'dropout': 0.2, 'num_experts': 7, 'aux_loss_weight': 0, 'unfrozen_layers': 2, 'top_k': 2, 'grad_accum_steps': 4}\n",
      "--------------------------------------------------------------------------------------------------------------------------------------- \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "165c04a774c84d9b96f9ff6e5bbc53e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/70 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5821c38e8bea49cfbcfdec0a287518d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expert assignment per essay_set:\n",
      "  Essay Set 2 → Expert 0\n",
      "  Essay Set 3 → Expert 1\n",
      "  Essay Set 4 → Expert 2\n",
      "  Essay Set 5 → Expert 3\n",
      "  Essay Set 6 → Expert 4\n",
      "  Essay Set 7 → Expert 5\n",
      "  Essay Set 8 → Expert 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50227ae60e6c4690b11a6c59cd716aa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/70 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " --------------------------------------------------\n",
      "Config 1/1 -> prompt_1 -> Test QWK: 0.0860\n",
      "-------------------------------------------------- \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9df294aea8954ca58cf185db09fd8096",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/70 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a03a0a4b3054440e95c58117d030a3ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expert assignment per essay_set:\n",
      "  Essay Set 1 → Expert 0\n",
      "  Essay Set 3 → Expert 1\n",
      "  Essay Set 4 → Expert 2\n",
      "  Essay Set 5 → Expert 3\n",
      "  Essay Set 6 → Expert 4\n",
      "  Essay Set 7 → Expert 5\n",
      "  Essay Set 8 → Expert 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "843ecc31a83049cd92990f6a086a67b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/70 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " --------------------------------------------------\n",
      "Config 1/1 -> prompt_2 -> Test QWK: 0.0000\n",
      "-------------------------------------------------- \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2245cddf82b24dd28cda0d1bb1a344d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/70 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5ec80f83ad844279a0ddc1000417f41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expert assignment per essay_set:\n",
      "  Essay Set 1 → Expert 0\n",
      "  Essay Set 2 → Expert 1\n",
      "  Essay Set 4 → Expert 2\n",
      "  Essay Set 5 → Expert 3\n",
      "  Essay Set 6 → Expert 4\n",
      "  Essay Set 7 → Expert 5\n",
      "  Essay Set 8 → Expert 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9dcbf239a144bd1a92b80eec52be3da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/70 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " --------------------------------------------------\n",
      "Config 1/1 -> prompt_3 -> Test QWK: 0.0000\n",
      "-------------------------------------------------- \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "919be626d10f411083a9ce55da4a5533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/70 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afbda6e47e62499995a79be2d48f0a7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expert assignment per essay_set:\n",
      "  Essay Set 1 → Expert 0\n",
      "  Essay Set 2 → Expert 1\n",
      "  Essay Set 3 → Expert 2\n",
      "  Essay Set 5 → Expert 3\n",
      "  Essay Set 6 → Expert 4\n",
      "  Essay Set 7 → Expert 5\n",
      "  Essay Set 8 → Expert 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca31e2a5dfc4410cb6066ae99654ac24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/70 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " --------------------------------------------------\n",
      "Config 1/1 -> prompt_4 -> Test QWK: 0.3023\n",
      "-------------------------------------------------- \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "006a79f912f348b9ae9bd4615f24d7a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/70 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff6684e5f4b84544a69cbd1e6c2cba6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expert assignment per essay_set:\n",
      "  Essay Set 1 → Expert 0\n",
      "  Essay Set 2 → Expert 1\n",
      "  Essay Set 3 → Expert 2\n",
      "  Essay Set 4 → Expert 3\n",
      "  Essay Set 6 → Expert 4\n",
      "  Essay Set 7 → Expert 5\n",
      "  Essay Set 8 → Expert 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ed1d7a418394c04b51e6d2ed3aa6da1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/70 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " --------------------------------------------------\n",
      "Config 1/1 -> prompt_5 -> Test QWK: -0.0149\n",
      "-------------------------------------------------- \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f6295125e8440b79bd1392201a5ce1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/70 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53df59b6d947403dbe9064b0b581b952",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expert assignment per essay_set:\n",
      "  Essay Set 1 → Expert 0\n",
      "  Essay Set 2 → Expert 1\n",
      "  Essay Set 3 → Expert 2\n",
      "  Essay Set 4 → Expert 3\n",
      "  Essay Set 5 → Expert 4\n",
      "  Essay Set 7 → Expert 5\n",
      "  Essay Set 8 → Expert 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b72edd3fd274873abe2f404d6b4cbaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/70 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " --------------------------------------------------\n",
      "Config 1/1 -> prompt_6 -> Test QWK: -0.0580\n",
      "-------------------------------------------------- \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf2d2a9fc1414665be6cd6d5a72a45b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/70 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1a7fbbc4f8547768a3b506a080a9198",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expert assignment per essay_set:\n",
      "  Essay Set 1 → Expert 0\n",
      "  Essay Set 2 → Expert 1\n",
      "  Essay Set 3 → Expert 2\n",
      "  Essay Set 4 → Expert 3\n",
      "  Essay Set 5 → Expert 4\n",
      "  Essay Set 6 → Expert 5\n",
      "  Essay Set 8 → Expert 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b57fab9ac8104fd681335c1133eb4b6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/70 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " --------------------------------------------------\n",
      "Config 1/1 -> prompt_7 -> Test QWK: 0.1411\n",
      "-------------------------------------------------- \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "086bcdc8740a4fef8c7f6cbbfac3fc32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/70 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40d40d0139a34f4593a4b56b134fa7ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expert assignment per essay_set:\n",
      "  Essay Set 1 → Expert 0\n",
      "  Essay Set 2 → Expert 1\n",
      "  Essay Set 3 → Expert 2\n",
      "  Essay Set 4 → Expert 3\n",
      "  Essay Set 5 → Expert 4\n",
      "  Essay Set 6 → Expert 5\n",
      "  Essay Set 7 → Expert 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87ce4eec5bd6412a82df34ed5b4625dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/70 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " --------------------------------------------------\n",
      "Config 1/1 -> prompt_8 -> Test QWK: -0.1240\n",
      "-------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Main training + evaluation loop ---\n",
    "# Purpose:\n",
    "# Runs multiple experiments across different hyperparameter configs and cross-prompt splits.\n",
    "# - Prepares data for each split\n",
    "# - Builds and trains a MoeBERTScorer model\n",
    "# - Evaluates on the test set\n",
    "# - Logs performance and gating stats to a CSV\n",
    "\n",
    "splits = generate_train7_test1_splits()  # Create 8-fold cross-prompt train/test splits\n",
    "results = []\n",
    "\n",
    "# Load BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Loop over all hyperparameter configurations\n",
    "for config_id, values in enumerate(config_list):\n",
    "    config = dict(zip(config_keys, values))  # Map config values to their names\n",
    "\n",
    "    # Skip configs that have already been run\n",
    "    if config in existing_configs:\n",
    "        print(f\"*** Skipping Config {config_id+1}/{len(config_list)} — already completed ***\")\n",
    "        continue\n",
    "\n",
    "    # Print config header\n",
    "    print(\"\\n\", \"-\"*135)\n",
    "    print(f\"\\nRunning Config {config_id+1}/{len(config_list)}: {config}\")\n",
    "    print(\"-\"*135, \"\\n\")\n",
    "\n",
    "    test_qwks = []  # Store QWK results for each test prompt\n",
    "\n",
    "    # Loop over each train/test split\n",
    "    for split in splits:\n",
    "        # Separate training and test data by essay_set\n",
    "        train_df = df[df[\"essay_set\"].isin(split[\"train\"])].copy()\n",
    "        test_df  = df[df[\"essay_set\"] == split[\"test\"]].copy()\n",
    "\n",
    "        # Convert DataFrames to Hugging Face Dataset objects\n",
    "        train_dataset = Dataset.from_pandas(train_df)\n",
    "        test_dataset  = Dataset.from_pandas(test_df)\n",
    "\n",
    "        # Tokenize text and extract handcrafted features\n",
    "        train_dataset = train_dataset.map(lambda ex: preprocess(ex, tokenizer))\n",
    "        test_dataset  = test_dataset.map(lambda ex: preprocess(ex, tokenizer))\n",
    "\n",
    "        # Create a fixed mapping from essay_set → expert index (train only)\n",
    "        expert_map = map_essay_set_to_expert(split[\"train\"])\n",
    "        print(\"Expert assignment per essay_set:\")\n",
    "        for es, expert_id in expert_map.items():\n",
    "            print(f\"  Essay Set {es} → Expert {expert_id}\")\n",
    "\n",
    "        # Add expert_mask to training set (used for gating supervision)\n",
    "        train_dataset = train_dataset.map(lambda ex: add_expert_mask(ex, expert_map))\n",
    "        # Note: test_dataset does NOT get expert_mask (soft gating only on unseen prompts)\n",
    "\n",
    "        # Number of handcrafted features per essay\n",
    "        n_handcrafted_features = len(train_dataset[0][\"features\"])\n",
    "\n",
    "        # Configure and create the MoE BERT model\n",
    "        bert_config = BertConfig.from_pretrained(\"bert-base-uncased\")\n",
    "        moe_model = MoeBERTModel(\n",
    "            bert_config,\n",
    "            num_experts=config[\"num_experts\"],\n",
    "            top_k=config[\"top_k\"],\n",
    "            pretrained_name_or_path=\"bert-base-uncased\"\n",
    "        )\n",
    "        model = MoeBERTScorer(\n",
    "            base_model=moe_model,\n",
    "            dropout=config[\"dropout\"],\n",
    "            feature_dim=n_handcrafted_features\n",
    "        ).to(device)\n",
    "\n",
    "        # Freeze lower BERT layers according to config\n",
    "        freeze_bert_layers(model.encoder, num_unfrozen=config[\"unfrozen_layers\"])\n",
    "        model.encoder.config.aux_loss_weight = config[\"aux_loss_weight\"]\n",
    "\n",
    "        # Gradient accumulation steps (to simulate larger batch sizes)\n",
    "        grad_accum_steps = int(config.get(\"grad_accum_steps\", 4))\n",
    "\n",
    "        # Hugging Face training arguments\n",
    "        training_args = TrainingArguments(\n",
    "            per_device_train_batch_size=config[\"batch_size\"],\n",
    "            per_device_eval_batch_size=config[\"batch_size\"],\n",
    "            learning_rate=config[\"learning_rate\"],\n",
    "            num_train_epochs=config[\"epochs\"],\n",
    "            output_dir=\"./checkpoints\",\n",
    "            label_names=[\"labels\"],\n",
    "            logging_strategy=\"no\",\n",
    "            eval_strategy=\"no\",\n",
    "            save_strategy=\"no\",\n",
    "            report_to=\"none\",\n",
    "            max_grad_norm=1.0,\n",
    "            weight_decay=0.01,\n",
    "            warmup_ratio=0.1,\n",
    "            gradient_accumulation_steps=grad_accum_steps, \n",
    "        )\n",
    "\n",
    "        # Trainer handles training loop, batching, and optimization\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=train_dataset,\n",
    "            tokenizer=tokenizer,\n",
    "            data_collator=data_collator,\n",
    "        )\n",
    "\n",
    "        trainer.train()  # Train the model\n",
    "\n",
    "        # ---- Evaluation on test set ----\n",
    "        test_predictions = trainer.predict(test_dataset)\n",
    "\n",
    "        # Extract predictions array\n",
    "        raw_preds = test_predictions.predictions\n",
    "        if isinstance(raw_preds, (list, tuple)):\n",
    "            raw_preds = raw_preds[0]\n",
    "        raw_preds = np.squeeze(raw_preds)\n",
    "\n",
    "        raw_labels = np.squeeze(test_predictions.label_ids)\n",
    "\n",
    "        # Convert scores back to original scale\n",
    "        test_preds  = denormalize_score(raw_preds,  test_df)\n",
    "        test_labels = denormalize_score(raw_labels, test_df)\n",
    "\n",
    "        # ---- Gating statistics ----\n",
    "        gate_weights = model.last_gate_weights.numpy()  # avg gate weights per sequence\n",
    "        avg_gate_weights = gate_weights.mean(axis=0)    # mean across batch\n",
    "        prob_dist = avg_gate_weights / (avg_gate_weights.sum() + 1e-12)\n",
    "        entropy = -(prob_dist * np.log(prob_dist + 1e-12)).sum()\n",
    "        top_expert = int(np.argmax(avg_gate_weights))\n",
    "\n",
    "        # Quadratic Weighted Kappa score for performance\n",
    "        qwk_test = cohen_kappa_score(test_labels, test_preds, weights=\"quadratic\")\n",
    "        test_qwks.append(qwk_test)\n",
    "\n",
    "        print(\"\\n\", \"-\"*50)\n",
    "        print(f\"Config {config_id+1}/{len(config_list)} -> prompt_{split['test']} -> Test QWK: {qwk_test:.4f}\")\n",
    "        print(\"-\"*50, \"\\n\")\n",
    "\n",
    "        # Save this run’s results\n",
    "        result_row = {\n",
    "            \"train_sets\": split[\"train\"],\n",
    "            \"test_set\": split[\"test\"],\n",
    "            \"prompt_test_qwk\": qwk_test,\n",
    "            \"gate_entropy\": entropy,\n",
    "            \"top_expert\": top_expert,\n",
    "            **{f\"pi_expert_{i}\": float(avg_gate_weights[i]) for i in range(len(avg_gate_weights))},\n",
    "            **config\n",
    "        }\n",
    "\n",
    "        results_df = pd.DataFrame([result_row])\n",
    "        results_csv_path = f\"{RESULTS_DIR}/BERT/BERT_results_1.csv\"\n",
    "        if os.path.exists(results_csv_path):\n",
    "            results_df.to_csv(results_csv_path, mode=\"a\", header=False, index=False)\n",
    "        else:\n",
    "            results_df.to_csv(results_csv_path, mode=\"w\", header=True, index=False)\n",
    "\n",
    "        # Free GPU memory\n",
    "        del trainer, model\n",
    "        torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# coding: utf-8",
   "executable": "/usr/bin/env python",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python [conda env:aes_env]",
   "language": "python",
   "name": "conda-env-aes_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
